# Configurações padrão do Apache Spark para Big Data Project

# Configurações básicas da aplicação
spark.app.name                     BigDataFinanceAnalysis
spark.master                       spark://spark-master:7077
spark.submit.deployMode            client

# Configurações de memória e cores
spark.driver.memory                2g
spark.driver.cores                 2
spark.executor.memory              2g
spark.executor.cores               2
spark.executor.instances           2

# Configurações de rede
spark.driver.host                  0.0.0.0
spark.driver.bindAddress           0.0.0.0
spark.blockManager.port            7079

# Configurações do HDFS
spark.hadoop.fs.defaultFS          hdfs://namenode:9000
spark.eventLog.enabled             true
spark.eventLog.dir                 hdfs://namenode:9000/spark-logs
spark.history.fs.logDirectory      hdfs://namenode:9000/spark-logs

# Configurações de serialização
spark.serializer                   org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired    false

# Configurações de SQL e DataFrame
spark.sql.adaptive.enabled         true
spark.sql.adaptive.coalescePartitions.enabled    true
spark.sql.adaptive.skewJoin.enabled              true
spark.sql.warehouse.dir            hdfs://namenode:9000/user/hive/warehouse

# Configurações de Delta Lake
spark.sql.extensions               io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog    org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.databricks.delta.retentionDurationCheck.enabled    false

# Configurações de checkpoint
spark.sql.streaming.checkpointLocation    hdfs://namenode:9000/checkpoints

# Configurações de compressão
spark.sql.parquet.compression.codec    snappy
spark.io.compression.codec             snappy

# Configurações de UI
spark.ui.port                      4040
spark.ui.enabled                   true

# Configurações de logs
spark.eventLog.compress            true
spark.eventLog.rolling.enabled     true
spark.eventLog.rolling.maxFileSize 128m

# Configurações de segurança (desabilitadas para desenvolvimento)
spark.authenticate                 false
spark.network.crypto.enabled      false
spark.io.encryption.enabled       false

# Configurações específicas para análise financeira
spark.sql.execution.arrow.pyspark.enabled    true
spark.sql.execution.arrow.maxRecordsPerBatch 10000

# Configurações de timeout
spark.network.timeout             300s
spark.executor.heartbeatInterval  30s

# Configurações de garbage collection
spark.executor.extraJavaOptions   -XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions -XX:+G1PrintRegionRememberSetInfo -XX:OnOutOfMemoryError='kill -9 %p' -XX:G1HeapRegionSize=32m
spark.driver.extraJavaOptions     -XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions -XX:+G1PrintRegionRememberSetInfo -XX:OnOutOfMemoryError='kill -9 %p' -XX:G1HeapRegionSize=32m